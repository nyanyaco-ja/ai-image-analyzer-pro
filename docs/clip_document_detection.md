# CLIP文書画像検出機能 (v1.6.1)

## 概要

CLIP（Contrastive Language-Image Pre-training）は自然画像に対しては優れた意味的類似度評価を提供しますが、**文書/テキスト主体の画像（医療カルテ、レシート、スキャン文書など）に対しては構造的類似性を過大評価する傾向**があります。

この問題を解決するため、v1.6.1では**文書画像自動検出機能と厳格な評価基準**を実装しました。

---

## 問題の詳細

### 発生した問題

医療カルテ画像の分析時、以下のような誤判定が発生：

```
元画像: 医療カルテA（患者情報: 田中太郎、診断: インフルエンザ）
画像1:  医療カルテB（患者情報: 佐藤花子、診断: 骨折）
画像2:  医療カルテC（患者情報: 鈴木一郎、診断: 高血圧）

CLIP類似度結果:
- 画像1 vs 元画像: 0.9356  ← 全く異なる患者なのに高スコア
- 画像2 vs 元画像: 0.9040  ← 全く異なる患者なのに高スコア
```

### 根本原因

1. **CLIPの訓練データ**: CLIPは主に自然画像（風景、動物、人物写真など）で訓練されている
2. **構造的類似性**: 医療カルテは以下の特徴を共有するため、CLIPが「類似」と判定
   - 白背景が多い
   - テキストレイアウトが似ている
   - フォーマットが統一されている（ヘッダー、本文、署名欄など）
3. **内容の無視**: CLIPは画像の"構造"は見ているが、テキストの"内容"（患者名、診断名）は正確に読み取れない

---

## 実装した解決策

### 1. 文書画像自動検出機能

**関数**: `is_document_image(img_rgb)` (`advanced_image_analyzer.py:188`)

医療カルテ、スキャン文書、レシートなどを自動検出します。

#### 検出アルゴリズム

```python
# 1. 白背景率を計算
白背景率 = (RGB値がすべて240以上のピクセル数) / 総ピクセル数

# 2. 色分散を計算（文書は色のバリエーションが少ない）
色分散 = np.std(img_rgb)

# 3. グレースケール率を計算（文書は白黒が多い）
グレースケール率 = (RGBの差が30未満のピクセル数) / 総ピクセル数

# 判定基準
文書画像 = (白背景率 > 60% AND 色分散 < 50) OR
          (グレースケール率 > 80% AND 白背景率 > 40%)
```

#### 検出例

| 画像タイプ | 白背景率 | 色分散 | グレー率 | 判定 |
|---------|---------|-------|---------|------|
| 医療カルテ | 93.1% | 55.7 | 100.0% | ✅ 文書 |
| スキャン文書 | 79.2% | 91.4 | 100.0% | ✅ 文書 |
| 自然画像（風景） | 0.0% | 59.0 | 0.0% | ❌ 自然画像 |
| 写真 | 0.0% | 43.3 | 10.1% | ❌ 自然画像 |

---

### 2. 文書画像用の厳格な評価基準

文書画像が検出された場合、CLIPの評価閾値を大幅に引き上げます。

#### 閾値の比較

| 評価 | 自然画像（通常） | 文書画像（厳格） | 変更理由 |
|------|--------------|--------------|----------|
| 意味的にほぼ同一 | > 0.95 | > 0.98 | 文書は0.95でも異なる可能性 |
| 意味的に類似 | > 0.85 | > 0.95 | 構造類似で高スコアになりやすい |
| 要注意（構造類似） | - | > 0.90 | 文書専用の警告レベル |
| 全く異なる | ≤ 0.85 | ≤ 0.90 | より厳格な基準 |

#### 実装箇所

1. **advanced_image_analyzer.py (1217-1243行目)**
   - CLIP計算時に文書検出を実行
   - 検出された場合、厳格な閾値で評価メッセージを表示

2. **result_interpreter.py (159-230行目)**
   - 解釈時にも文書フラグを確認
   - 文書画像には警告マークを追加

3. **result_interpreter.py (632-689行目)**
   - 幻覚検出の閾値を動的に調整
   - 文書画像: 0.90未満で警告（通常: 0.70未満）

---

### 3. 出力例の変更

#### Before（v1.6）- 誤検出

```
【3.6. CLIP Embeddings（意味的類似度）】
画像1 vs 元画像 CLIP: 0.9356
画像2 vs 元画像 CLIP: 0.9040
→ 画像1の方が元画像に意味的に近い
  画像1: 意味的に非常に類似  ← 誤った評価
  画像2: 意味的に非常に類似  ← 誤った評価
```

#### After（v1.6.1）- 正確な警告

```
【3.6. CLIP Embeddings（意味的類似度）】
  📄 文書画像を検出 (白背景: 93.1%, 色分散: 55.7, グレー率: 100.0%)
  📄 文書画像を検出 (白背景: 79.2%, 色分散: 91.4, グレー率: 100.0%)
  📄 文書画像を検出 (白背景: 85.3%, 色分散: 68.2, グレー率: 100.0%)
  ⚠️  文書/カルテ画像を検出: CLIPは厳格な基準で評価します
画像1 vs 元画像 CLIP: 0.9356
画像2 vs 元画像 CLIP: 0.9040
→ 画像1の方が元画像に意味的に近い
  画像1: 意味的に類似（要注意：文書は構造類似で高スコアになりやすい）
  画像2: ⚠️ 構造は類似だが内容は異なる可能性 🔍  ← 正しい警告
```

#### 幻覚検出の変更

```
【🔬 CLIP + LPIPS 統合幻覚検出】
📄 文書/カルテ画像検出: CLIPに厳格な基準を適用
⚠️ 警告【画像1】: CLIP類似度低 (< 0.90) - 意味的に異なる画像の可能性
🚨 重大警告【画像2】: CLIP & LPIPS両方で異常検出 - 幻覚の可能性が極めて高い (CLIP: 0.9040 < 0.90)
```

---

## 対応画像タイプ

### ✅ 文書として検出される画像

- 医療カルテ（電子カルテ、手書きカルテ）
- 診療報酬明細書
- 処方箋
- レントゲン画像の読影レポート
- レシート、領収書
- 契約書、請求書
- スキャンされた文書
- 白黒のテキスト主体の画像

### ❌ 自然画像として扱われる画像

- 医療画像（レントゲン、CT、MRI）※文書ではないため
- 顕微鏡画像
- 衛星画像
- 風景写真
- 人物写真
- アニメ・イラスト

---

## 技術詳細

### データ構造の変更

#### advanced_image_analyzer.py の results 辞書

**Before（v1.6）:**
```python
results['clip_similarity'] = {
    'img1_vs_original': 0.9356,
    'img2_vs_original': 0.9040
}
```

**After（v1.6.1）:**
```python
results['clip_similarity'] = {
    'img1_vs_original': 0.9356,
    'img2_vs_original': 0.9040,
    'is_document': True  # ← 文書フラグを追加
}
```

### 閾値の動的調整

```python
# result_interpreter.py 632-639行目
if is_document:
    clip_threshold_error = 0.90   # 通常 0.70 → 文書 0.90
    clip_threshold_good = 0.95    # 通常 0.85 → 文書 0.95
else:
    clip_threshold_error = 0.70
    clip_threshold_good = 0.85
```

---

## テスト結果

### 単体テスト

`test_document_detection_simple.py` による検証:

```
【テスト1】白背景の医療カルテ風画像
  白背景率: 93.1%, 色分散: 55.7, グレー率: 100.0%
  判定: 文書画像 📄
  ✅ 期待: 文書画像 → 正解

【テスト2】カラフルな自然画像
  白背景率: 0.0%, 色分散: 59.0, グレー率: 0.0%
  判定: 自然画像 🖼️
  ✅ 期待: 自然画像 → 正解

【テスト3】スキャン文書風画像
  白背景率: 79.2%, 色分散: 91.4, グレー率: 100.0%
  判定: 文書画像 📄
  ✅ 期待: 文書画像 → 正解

【テスト4】通常の写真
  白背景率: 0.0%, 色分散: 43.3, グレー率: 10.1%
  判定: 自然画像 🖼️
  ✅ 期待: 自然画像 → 正解
```

### 実運用テスト

医療カルテ3枚（全く異なる患者データ）での検証:

**Before（v1.6）:**
- 画像1: CLIP 0.9356 → 評価「意味的に非常に類似」❌
- 画像2: CLIP 0.9040 → 評価「意味的に非常に類似」❌

**After（v1.6.1）:**
- 画像1: CLIP 0.9356 → 評価「意味的に類似（要注意：文書は構造類似で高スコアになりやすい）」✅
- 画像2: CLIP 0.9040 → 評価「⚠️ 構造は類似だが内容は異なる可能性 🔍」✅

---

## 制限事項

### CLIPの限界

1. **テキスト内容の認識不可**: CLIPはOCR機能を持たないため、カルテのテキスト内容（患者名、診断名）を読み取れない
2. **構造的類似性への依存**: 同じフォーマットの文書は高スコアになる傾向がある
3. **完全な区別は不可能**: 0.90-0.95の範囲では判別が困難

### 推奨される併用指標

文書画像の場合、CLIPだけでなく以下の指標も併用することを推奨：

1. **PSNR**: ピクセルレベルの正確な一致を評価
2. **SSIM**: 構造的類似度（文書のレイアウト変更を検出）
3. **LPIPS**: 知覚的類似度（人間の見た目の判断に近い）

---

## 今後の改善案

### Option A: OCRベースの内容比較（未実装）

```python
# 将来的な実装案
def compare_document_content(img1, img2):
    # OCRでテキスト抽出
    text1 = pytesseract.image_to_string(img1, lang='jpn')
    text2 = pytesseract.image_to_string(img2, lang='jpn')

    # テキスト類似度計算
    similarity = difflib.SequenceMatcher(None, text1, text2).ratio()
    return similarity
```

**メリット**:
- 患者名、診断名などの実際の内容を比較可能
- 医療カルテの正確な一致判定

**デメリット**:
- OCR精度に依存（手書き文字は困難）
- pytesseract等の追加依存関係
- 処理時間の増加

### Option B: 文書専用モデルの導入（未実装）

```python
# LayoutLMv3やDonutなどの文書理解モデル
from transformers import LayoutLMv3Model
model = LayoutLMv3Model.from_pretrained("microsoft/layoutlmv3-base")
```

**メリット**:
- 文書レイアウトとテキストの両方を理解
- 医療文書に特化した判定が可能

**デメリット**:
- モデルサイズが大きい（数GB）
- 学習データが必要（医療文書のデータセット）

---

## 関連ファイル

### 実装ファイル
- `advanced_image_analyzer.py:188-229` - `is_document_image()` 関数
- `advanced_image_analyzer.py:1191-1249` - CLIP計算と文書検出
- `result_interpreter.py:159-230` - 文書対応の解釈ロジック
- `result_interpreter.py:632-689` - 文書対応の幻覚検出

### テストファイル
- `test_document_detection_simple.py` - 単体テスト

### ドキュメント
- `docs/clip_feature_guide.md` - CLIP機能ガイド
- `RELEASE_NOTES_v1.6.md` - v1.6リリースノート

---

## まとめ

この機能により、CLIPが苦手とする**医療カルテ・文書画像に対しても適切な警告を表示**できるようになりました。

✅ **自動検出**: 白背景率・色分散・グレースケール率で文書を自動判定
✅ **厳格な基準**: 文書画像には通常の1.2倍厳しい閾値を適用
✅ **明確な警告**: ユーザーに「構造類似で高スコアになりやすい」と警告
✅ **後方互換性**: 自然画像（レントゲン、風景写真など）には従来通りの基準

**注意**: CLIPはあくまで補助指標です。医療カルテの正確な一致判定には、PSNR・SSIM・LPIPSとの併用を推奨します。
