# バッチ処理システム 完全ガイド

## 目次

1. [概要](#概要)
2. [システム構成](#システム構成)
3. [仕組みの詳細](#仕組みの詳細)
4. [機能一覧](#機能一覧)
5. [使用方法](#使用方法)
6. [出力ファイル詳細](#出力ファイル詳細)
7. [統計分析の解釈方法](#統計分析の解釈方法)
8. [医療画像での活用](#医療画像での活用)
9. [トラブルシューティング](#トラブルシューティング)

---

## 概要

### このシステムは何をするのか

**目的：** 大量の画像ペア（100枚以上）を自動で分析し、**統計的に根拠のある品質評価基準**を決定する

**従来の問題点：**
- GUIで1枚ずつ分析 → 300枚なら300回操作が必要
- 閾値（PSNR > 30とか）に科学的根拠がない
- ハルシネーション（AIが作った偽のディテール）を検出できない

**このシステムの解決策：**
1. **自動化** → フォルダ指定だけで300枚を自動処理
2. **データ駆動** → 実際のデータから統計的に閾値を決定
3. **ハルシネーション検出** → 複数の指標の矛盾パターンを発見

---

## システム構成

```
AI画像比較分析ツール
├── modern_gui.py              # GUI版（1枚ずつ分析）
├── advanced_image_analyzer.py # コア分析エンジン（17項目計算）
│
├── batch_analyzer.py          # ★ バッチ処理（大量画像自動分析）
├── analyze_results.py         # ★ 統計分析（閾値決定）
│
└── batch_config.json          # 設定ファイル（フォルダパス指定）
```

### データフロー

```
[元画像100枚] ─┬─> [AI超解像モデル1] ─> [超解像画像100枚]
               ├─> [AI超解像モデル2] ─> [超解像画像100枚]
               └─> [AI超解像モデル3] ─> [超解像画像100枚]
                                              ↓
                                    batch_analyzer.py
                                      （17項目×300枚計算）
                                              ↓
                                    batch_analysis.csv
                                      （300行のデータ）
                                              ↓
                                    analyze_results.py
                                      （統計分析）
                                              ↓
                      ┌─────────────────┬─────────────────┐
                      ↓                 ↓                 ↓
            recommended_thresholds.json  correlation_matrix.png  results_with_risk_score.csv
               （推奨閾値）              （相関分析）         （ハルシネーション検出）
```

---

## 仕組みの詳細

### 1. batch_analyzer.py の仕組み

#### **入力**
```
batch_config.json の内容:
{
  "original_dir": "dataset/original/",      # 元画像フォルダ
  "upscaled_dirs": {                        # 超解像画像フォルダ（複数）
    "model_A": "dataset/model_A/",
    "model_B": "dataset/model_B/",
    "model_C": "dataset/model_C/"
  },
  "output_csv": "results/batch_analysis.csv"
}
```

#### **処理の流れ**

```python
# 擬似コード
for 元画像 in 元画像フォルダ:
    for モデル名, 超解像フォルダ in 全モデル:
        # 対応する超解像画像を探す
        超解像画像 = 超解像フォルダ / 元画像と同じファイル名

        # 17項目分析を実行（advanced_image_analyzer.pyを呼び出し）
        結果 = analyze_images(元画像, 超解像画像, 元画像)

        # 17項目を抽出
        行データ = {
            'image_id': ファイル名,
            'model': モデル名,
            'ssim': 結果['ssim'],
            'psnr': 結果['psnr'],
            'sharpness': 結果['sharpness']['img2'],
            ... (17項目すべて)
        }

        # CSVに追加
        全結果.append(行データ)

# CSV保存
save_to_csv(全結果, "batch_analysis.csv")
```

#### **出力：CSV形式**

| image_id | model | ssim | psnr | lpips | sharpness | contrast | ... | total_score |
|----------|-------|------|------|-------|-----------|----------|-----|-------------|
| img001   | modelA| 0.945| 34.2 | 0.123 | 78.3      | 65.2     | ... | 82.5        |
| img001   | modelB| 0.932| 31.8 | 0.145 | 81.2      | 68.1     | ... | 85.1        |
| img001   | modelC| 0.921| 30.5 | 0.167 | 75.8      | 62.3     | ... | 79.8        |
| img002   | modelA| 0.938| 33.1 | 0.135 | 79.1      | 66.5     | ... | 83.2        |
| ...      | ...   | ...  | ...  | ...   | ...       | ...      | ... | ...         |

**合計300行**（100枚 × 3モデル）

---

### 2. analyze_results.py の仕組み

#### **入力**
`batch_analysis.csv`（300行のデータ）

#### **処理内容**

##### **A. 基本統計量計算**
```python
各指標について:
    平均値 = データの平均
    標準偏差 = データのばらつき
    最小値 = 最悪ケース
    最大値 = 最良ケース
    25パーセンタイル = 下位25%の境界
    75パーセンタイル = 上位25%の境界
```

**例：SSIMの統計**
```
平均: 0.9345
標準偏差: 0.0234
最小: 0.8521
25%: 0.9156
50%: 0.9378  ← 中央値
75%: 0.9567
最大: 0.9812
```

##### **B. 閾値決定ロジック**

```python
# 高い方が良い指標（SSIM, PSNR, シャープネスなど）
推奨閾値 = 25パーセンタイル
# → 上位75%を「合格」とする基準

# 例：SSIM
25パーセンタイル = 0.9156
推奨閾値: SSIM >= 0.9156
意味: 「全データの75%がこの値を超えている」

# 低い方が良い指標（ノイズ, アーティファクトなど）
推奨閾値 = 75パーセンタイル
# → 下位75%を「合格」とする基準

# 例：ノイズ
75パーセンタイル = 18.3
推奨閾値: ノイズ <= 18.3
意味: 「全データの75%がこの値以下」
```

**なぜ25/75パーセンタイル？**
- **保守的な基準** → 上位75%を合格にする = 品質保証
- **外れ値の影響を受けにくい** → 平均値だと異常値に引っ張られる
- **業界標準** → 多くの品質管理で使用される基準

##### **C. 相関分析**

17項目間の相関係数を計算：

```
         ssim   psnr  lpips  sharpness  noise  ...
ssim     1.00   0.82  -0.76   0.45      -0.38  ...
psnr     0.82   1.00  -0.68   0.52      -0.41  ...
lpips   -0.76  -0.68   1.00  -0.39       0.34  ...
sharpness 0.45   0.52  -0.39   1.00       0.12  ...
noise   -0.38  -0.41   0.34   0.12       1.00  ...
```

**相関係数の意味：**
- `+1.0` → 完全に正の相関（一方が増えると他方も増える）
- `0.0` → 相関なし
- `-1.0` → 完全に負の相関（一方が増えると他方は減る）

**活用例：**
```
SSIM と PSNR の相関 = 0.82 (高い正の相関)
→ 正常：両方とも「元画像との一致度」を測る指標なので相関して当然

SSIM が高いのに PSNR が低い画像を発見
→ 異常：構造は似てるがピクセル値が違う = ハルシネーションの疑い
```

##### **D. ハルシネーション検出ロジック**

**4つの異常パターンを検出：**

**パターン1: SSIM高 & PSNR低**
```python
条件: SSIM >= 0.95 AND PSNR <= 28
意味: 構造は似てるが、ピクセル値が大きく違う
疑い: AIが構造を「真似た」が、正確には再現していない
リスク: 中～高
```

**パターン2: シャープネス高 & ノイズ高**
```python
条件: シャープネス >= 85 AND ノイズ >= 20
意味: 鮮明だが、ノイズも増えている
疑い: 過度なシャープ化処理
リスク: 中
```

**パターン3: アーティファクト高**
```python
条件: アーティファクト >= 15
意味: リンギング・ブロックノイズが多い
疑い: GAN特有の歪み
リスク: 高（医療画像では診断阻害）
```

**パターン4: 局所品質のばらつき大**
```python
条件: 局所SSIM標準偏差 >= 0.15
意味: 場所によって品質が大きく異なる
疑い: 一部領域でハルシネーション発生
リスク: 中～高
```

**総合リスクスコア計算：**
```python
リスクスコア = 0
if パターン1該当: リスクスコア += 25
if パターン2該当: リスクスコア += 20
if パターン3該当: リスクスコア += 30
if パターン4該当: リスクスコア += 25

# リスクレベル分類
0-10:   MINIMAL (最小リスク)
10-30:  LOW     (低リスク)
30-50:  MEDIUM  (中リスク)
50-100: HIGH    (高リスク)
```

---

## 機能一覧

### batch_analyzer.py の機能

| 機能 | 説明 |
|------|------|
| **自動ペアリング** | ファイル名でペアを自動検出（img001.png ↔ img001.png） |
| **進捗表示** | tqdmプログレスバーで進行状況を表示 |
| **エラー耐性** | 1枚エラーでも処理を継続、最後に成功/失敗を報告 |
| **PNG/JPG対応** | 拡張子を自動判定 |
| **CSV出力** | UTF-8 BOM付き（Excel対応） |
| **簡易統計** | モデル別平均スコアを即座に表示 |
| **詳細レポート** | 各画像ペアの可視化レポートも保存可能 |

### analyze_results.py の機能

| 機能 | 説明 |
|------|------|
| **基本統計量** | 平均・標準偏差・四分位数など |
| **モデル比較** | モデル別の性能ランキング |
| **相関分析** | 17項目間の相関ヒートマップ |
| **閾値提案** | 統計的根拠のある推奨閾値 |
| **ハルシネーション検出** | 4つの異常パターンを自動検出 |
| **リスクスコア** | 各画像のハルシネーションリスクを定量化 |
| **可視化** | グラフ・ヒートマップを自動生成 |
| **CSV出力** | リスクスコア付き結果を保存 |

---

## 使用方法

### 準備：フォルダ構成

```
your_project/
├── dataset/
│   ├── original/          # 元画像100枚（1000px）
│   │   ├── chest001.png
│   │   ├── chest002.png
│   │   └── ...
│   │
│   ├── upscayl_model1/    # モデル1の超解像結果100枚
│   │   ├── chest001.png   # ← 同じファイル名
│   │   ├── chest002.png
│   │   └── ...
│   │
│   ├── upscayl_model2/    # モデル2の超解像結果100枚
│   │   └── ...
│   │
│   └── upscayl_model3/    # モデル3の超解像結果100枚
│       └── ...
│
└── image_compare/         # このツールのディレクトリ
    ├── batch_analyzer.py
    ├── analyze_results.py
    └── ...
```

### Step 1: 設定ファイル作成

```bash
cd image_compare
python batch_analyzer.py --create-config
```

**生成されるファイル：**
```json
// batch_config.json
{
  "original_dir": "dataset/original/",
  "upscaled_dirs": {
    "upscayl_model1": "dataset/upscayl_model1/",
    "upscayl_model2": "dataset/upscayl_model2/",
    "upscayl_model3": "dataset/upscayl_model3/"
  },
  "output_csv": "results/batch_analysis.csv",
  "output_detail_dir": "results/detailed/"
}
```

**編集ポイント：**
- パスは絶対パスでも相対パスでもOK
- Windowsの場合: `C:/dataset/original/` または `C:\\dataset\\original\\`
- モデル名は自由に変更可能（`"Real-ESRGAN"`, `"waifu2x"` など）

### Step 2: バッチ処理実行

```bash
python batch_analyzer.py batch_config.json
```

**実行中の表示例：**
```
============================================================
🚀 バッチ処理開始
============================================================
📁 元画像ディレクトリ: dataset/original/
🖼️  元画像数: 100枚
🤖 超解像モデル数: 3種類
   - upscayl_model1
   - upscayl_model2
   - upscayl_model3
💾 出力CSV: results/batch_analysis.csv
============================================================

元画像処理中: 100%|██████████████████| 100/100 [15:23<00:00,  9.23s/it]

============================================================
✅ バッチ処理完了！
============================================================
✔️  成功: 300 / 300
❌ エラー: 0 / 300
📄 結果CSV: results/batch_analysis.csv
📊 詳細レポート: results/detailed/
============================================================

📈 モデル別平均PSNR（AI超解像 vs Ground Truth）:
   upscayl_model2      : 34.52 dB
   upscayl_model1      : 32.18 dB
   upscayl_model3      : 30.91 dB
```

**所要時間の目安：**
- GPU（RTX 4050）: 約15-30分
- CPU のみ: 約1-2時間

### Step 3: 統計分析実行

```bash
python analyze_results.py results/batch_analysis.csv
```

**実行中の表示例：**
```
================================================================================
📊 統計分析レポート
================================================================================
📄 データファイル: results/batch_analysis.csv
📷 画像数: 100
🤖 モデル数: 3
📊 総データ数: 300
================================================================================

📈 主要指標の基本統計量:
================================================================================
              件数      平均  標準偏差      最小      25%      50%      75%      最大
ssim        300.0  0.9345   0.0234   0.8521   0.9156   0.9378   0.9567   0.9812
psnr        300.0  32.854   3.2145   25.123   30.567   32.891   35.012   41.234
lpips       300.0  0.1456   0.0312   0.0823   0.1234   0.1445   0.1678   0.2345
total_score 300.0  82.345   5.6789   68.234   78.567   82.891   86.234   94.567
...
================================================================================

🏆 モデル別ランキング:
================================================================================
                    ssim                psnr              lpips             total_score
                    mean    std         mean    std       mean    std       mean    std
upscayl_model2   0.9456  0.0189      34.521  2.891    0.1234  0.0234    85.234  4.123
upscayl_model1   0.9312  0.0234      32.178  3.234    0.1456  0.0289    82.456  5.234
upscayl_model3   0.9234  0.0267      30.912  3.567    0.1678  0.0345    79.678  6.123
================================================================================

💡 推奨閾値の提案:
================================================================================
SSIM（構造類似性）             : >= 0.9156       (平均: 0.9345, 標準偏差: 0.0234)
PSNR（信号対雑音比）           : >= 30.5670      (平均: 32.8540, 標準偏差: 3.2145)
LPIPS（知覚的類似度）          : <= 0.1678       (平均: 0.1456, 標準偏差: 0.0312)
ノイズレベル                   : <= 18.3450      (平均: 15.2340, 標準偏差: 4.1230)
...
================================================================================

🔍 ハルシネーション検出ロジックの提案:
================================================================================
【パターン1】SSIM高 & PSNR低 (構造類似だがピクセル値相違)
   条件: SSIM >= 0.9567 AND PSNR <= 30.5670
   該当率: 8.7% (26/300件)
   リスク: 中～高（AIが構造を模倣した可能性）

【パターン2】シャープネス高 & ノイズ高 (過剰処理)
   条件: シャープネス >= 84.23 AND ノイズ >= 18.34
   該当率: 5.3% (16/300件)
   リスク: 中（過度なシャープ化によるノイズ増幅）

【パターン3】アーティファクト高 (GAN特有の歪み)
   条件: アーティファクト >= 14.56
   該当率: 10.0% (30/300件)
   リスク: 高（リンギング・ブロックノイズによる診断阻害）

【パターン4】局所品質のばらつき大 (不均一な処理)
   条件: 局所SSIM標準偏差 >= 0.1345
   該当率: 7.3% (22/300件)
   リスク: 中～高（領域によって品質が異なる = 一部にハルシネーション）
================================================================================

✅ 分析完了！
📁 結果保存先: analysis_output/
```

---

## 出力ファイル詳細

### 1. batch_analysis.csv

**場所:** `results/batch_analysis.csv`

**形式:** CSV（UTF-8 BOM付き、Excel対応）

**列構成（全40列以上）:**

| 列名 | 説明 | データ型 | 範囲 |
|------|------|----------|------|
| `image_id` | 画像ID（ファイル名） | 文字列 | - |
| `model` | 使用モデル名 | 文字列 | - |
| `original_path` | 元画像のパス | 文字列 | - |
| `upscaled_path` | 超解像画像のパス | 文字列 | - |
| `ssim` | SSIM（構造類似性） | 浮動小数点 | 0.0-1.0 |
| `ms_ssim` | MS-SSIM | 浮動小数点 | 0.0-1.0 |
| `psnr` | PSNR（信号対雑音比） | 浮動小数点 | 0-∞ dB |
| `lpips` | LPIPS（知覚的類似度） | 浮動小数点 | 0.0-1.0 |
| `sharpness` | シャープネス | 浮動小数点 | 0-100 |
| `contrast` | コントラスト | 浮動小数点 | 0-100 |
| `entropy` | エントロピー | 浮動小数点 | 0-8 |
| `noise` | ノイズレベル | 浮動小数点 | 0-100 |
| `edge_density` | エッジ密度 | 整数 | 0-∞ |
| `artifact_block` | ブロックノイズ | 浮動小数点 | 0-100 |
| `artifact_ringing` | リンギング | 浮動小数点 | 0-100 |
| `artifact_total` | アーティファクト合計 | 浮動小数点 | 0-200 |
| `delta_e` | 色差（ΔE） | 浮動小数点 | 0-100 |
| `high_freq_ratio` | 高周波成分比率 | 浮動小数点 | 0-1 |
| `texture_complexity` | テクスチャ複雑度 | 浮動小数点 | 0-100 |
| `local_quality_mean` | 局所品質平均 | 浮動小数点 | 0-1 |
| `local_quality_std` | 局所品質標準偏差 | 浮動小数点 | 0-1 |
| `local_quality_min` | 局所品質最小 | 浮動小数点 | 0-1 |
| `histogram_corr` | ヒストグラム相関 | 浮動小数点 | -1 to 1 |
| `lab_L_mean` | LAB明度平均 | 浮動小数点 | 0-100 |
| `total_score` | 総合スコア | 浮動小数点 | 0-100 |

**使用例（Excelで開く）:**
1. Excelで `batch_analysis.csv` を開く
2. ピボットテーブルで `model` 別に平均を集計
3. グラフ作成

**使用例（Python）:**
```python
import pandas as pd

df = pd.read_csv('results/batch_analysis.csv')

# モデル別平均
print(df.groupby('model')['total_score'].mean())

# 最高スコアの画像を探す
best = df.loc[df['total_score'].idxmax()]
print(f"Best image: {best['image_id']} by {best['model']}")
```

---

### 2. analysis_output/model_comparison.csv

**場所:** `analysis_output/model_comparison.csv`

**内容:** モデル別の統計サマリー

**例:**
```csv
model,ssim_mean,ssim_std,psnr_mean,psnr_std,total_score_mean,total_score_std
upscayl_model2,0.9456,0.0189,34.521,2.891,85.234,4.123
upscayl_model1,0.9312,0.0234,32.178,3.234,82.456,5.234
upscayl_model3,0.9234,0.0267,30.912,3.567,79.678,6.123
```

**活用方法:**
- どのモデルが最も優れているか
- どのモデルが最も安定しているか（標準偏差が小さい）

---

### 3. analysis_output/recommended_thresholds.json

**場所:** `analysis_output/recommended_thresholds.json`

**重要度:** ★★★★★（最重要ファイル）

**内容:** 統計的根拠のある閾値

**例:**
```json
{
  "ssim": {
    "name": "SSIM（構造類似性）",
    "threshold": 0.9156,
    "condition": ">= 0.9156",
    "mean": 0.9345,
    "std": 0.0234,
    "min": 0.8521,
    "max": 0.9812
  },
  "psnr": {
    "name": "PSNR（信号対雑音比）",
    "threshold": 30.567,
    "condition": ">= 30.567",
    "mean": 32.854,
    "std": 3.2145,
    "min": 25.123,
    "max": 41.234
  },
  "noise": {
    "name": "ノイズレベル",
    "threshold": 18.345,
    "condition": "<= 18.345",
    "mean": 15.234,
    "std": 4.123,
    "min": 8.234,
    "max": 28.456
  }
}
```

**この閾値の意味:**
- `threshold`: 推奨される基準値
- `condition`: 合格条件
- `mean`: 全データの平均
- `std`: ばらつき（小さいほど安定）

**活用方法:**
1. これをアプリに実装
2. 医療画像モードの品質判定基準として使用
3. 論文に引用（N=300のデータに基づく）

---

### 4. analysis_output/correlation_matrix.png

**場所:** `analysis_output/correlation_matrix.png`

**内容:** 17項目間の相関ヒートマップ

**見方:**
- **赤色（+1.0に近い）:** 正の相関（一緒に増える）
- **青色（-1.0に近い）:** 負の相関（逆に動く）
- **白色（0.0）:** 相関なし

**例の解釈:**
```
SSIM と PSNR: 相関 +0.82 (赤色)
→ 正常：両方とも品質指標なので一緒に良くなる

LPIPS と SSIM: 相関 -0.76 (青色)
→ 正常：LPIPSは「違い」を測るので、SSIMとは逆

シャープネス と ノイズ: 相関 +0.45 (薄い赤)
→ 注意：シャープにするとノイズも増える傾向
```

**異常パターンの発見:**
```
ある画像で:
SSIM = 0.95 (高い)
PSNR = 28.0 (低い)

相関マトリックスでは SSIM-PSNR = +0.82 なのに、
この画像だけ逆転している
→ ハルシネーションの疑い！
```

---

### 5. analysis_output/results_with_risk_score.csv

**場所:** `analysis_output/results_with_risk_score.csv`

**内容:** 元のCSVに `hallucination_risk_score` と `risk_level` を追加

**新しい列:**
- `hallucination_risk_score`: 0-100のリスクスコア
- `risk_level`: MINIMAL / LOW / MEDIUM / HIGH

**例:**
```csv
image_id,model,ssim,psnr,...,hallucination_risk_score,risk_level
chest001,modelA,0.945,34.2,...,0,MINIMAL
chest001,modelB,0.932,31.8,...,25,LOW
chest001,modelC,0.921,28.5,...,50,MEDIUM
chest002,modelA,0.938,33.1,...,0,MINIMAL
chest003,modelB,0.952,27.3,...,75,HIGH  ← 要注意！
```

**活用方法:**
```python
# HIGH リスクの画像を抽出
import pandas as pd

df = pd.read_csv('analysis_output/results_with_risk_score.csv')
high_risk = df[df['risk_level'] == 'HIGH']

print(f"HIGH リスク画像: {len(high_risk)}枚")
for _, row in high_risk.iterrows():
    print(f"  {row['image_id']} - {row['model']} (スコア: {row['hallucination_risk_score']})")
```

---

### 6. analysis_output/model_scores.png

**場所:** `analysis_output/model_scores.png`

**内容:** モデル別総合スコアの棒グラフ

**活用方法:**
- プレゼン資料に使用
- どのモデルが優れているか一目で分かる

---

## 統計分析の解釈方法

### パーセンタイルとは

**25パーセンタイル（第1四分位数）:**
- 全データを小さい順に並べて、25%の位置の値
- 例：100個のデータで25番目の値
- 意味：**上位75%の境界**

**75パーセンタイル（第3四分位数）:**
- 全データを小さい順に並べて、75%の位置の値
- 例：100個のデータで75番目の値
- 意味：**下位75%の境界**

**具体例（SSIMのデータ）:**
```
データ100個を小さい順に並べる:
[0.85, 0.87, 0.89, ..., 0.91, 0.92, 0.93, ..., 0.95, 0.96, 0.98]
 ↑                    ↑           ↑           ↑           ↑
最小                25%目       50%目       75%目       最大
0.85               0.9156      0.9378      0.9567      0.98

25パーセンタイル = 0.9156
→ 「75個（75%）がこの値を超えている」
→ 閾値として採用: SSIM >= 0.9156 なら「上位75%の品質」
```

### 閾値の厳しさ調整

**より厳しい基準が必要な場合:**
```python
# 50パーセンタイル（中央値）を使用
閾値 = 50パーセンタイル
→ 上位50%を合格にする（より厳しい）
```

**より緩い基準が必要な場合:**
```python
# 10パーセンタイルを使用
閾値 = 10パーセンタイル
→ 上位90%を合格にする（より緩い）
```

**医療画像の推奨:**
- 診断用画像: **25パーセンタイル**（厳しめ）
- 参考画像: **10パーセンタイル**（緩め）

### 相関係数の解釈

| 相関係数 | 意味 | 例 |
|----------|------|-----|
| 0.9-1.0 | 非常に強い正の相関 | SSIM と MS-SSIM |
| 0.7-0.9 | 強い正の相関 | SSIM と PSNR |
| 0.4-0.7 | 中程度の正の相関 | シャープネス と エッジ密度 |
| 0.2-0.4 | 弱い正の相関 | - |
| -0.2-0.2 | ほぼ相関なし | エントロピー と 明度 |
| -0.4--0.2 | 弱い負の相関 | - |
| -0.7--0.4 | 中程度の負の相関 | SSIM と ノイズ |
| -0.9--0.7 | 強い負の相関 | SSIM と LPIPS |
| -1.0--0.9 | 非常に強い負の相関 | - |

**異常な相関パターン:**
```
通常: SSIM と PSNR の相関 = +0.82

ある画像で:
SSIM = 高い
PSNR = 低い
→ 期待される相関から外れている
→ ハルシネーションの可能性
```

---

## 医療画像での活用

### NIH ChestX-ray14 データセットでの実験例

**データセット:**
- 元画像: 100枚の胸部X線（1024x1024 → 1000pxにダウンスケール）
- 超解像: 3つのAIモデルで2000pxに拡大
- 合計: 300ペア

**実験結果例:**

```
モデル別ランキング（PSNR基準）:
1位: SwinIR    - 36.8 dB （最も元画像に忠実）
2位: Real-ESRGAN - 33.2 dB
3位: waifu2x   - 31.5 dB

推奨閾値（X線画像）:
SSIM >= 0.94
PSNR >= 32.0 dB
ノイズ <= 15.0
アーティファクト <= 10.0

ハルシネーション検出結果:
HIGH リスク: 12件 (4%)
→ これらは診断使用不可
→ 詳細確認が必要
```

### 医療画像特有の注意点

**1. 病変部の保持確認**
```python
# 局所品質の分析が重要
local_quality_min < 0.90 の画像は要確認
→ 一部領域で品質が低下 = 病変が不鮮明になった可能性
```

**2. コントラストの変化**
```python
# X線では濃度値が診断の鍵
histogram_corr < 0.85 の画像は要確認
→ 濃度分布が変化 = CT値が不正確
```

**3. 偽の石灰化点の検出**
```python
# 高輝度の微小点が増えていないか
artifact_total > 15 の画像は要確認
→ GAN特有のアーティファクトが偽の所見を作る可能性
```

---

## トラブルシューティング

### エラー: "元画像が見つかりません"

**原因:** ファイル名が一致していない

**解決策:**
```bash
# 元画像フォルダ
ls dataset/original/
> chest001.png
> chest002.png

# 超解像フォルダ
ls dataset/upscayl_model1/
> chest_001.png  ← アンダースコアが違う！
> chest_002.png

# 修正: ファイル名を統一
cd dataset/upscayl_model1/
rename 's/chest_/chest/' *.png
```

### エラー: "Module not found: pandas"

**原因:** 必要なライブラリがインストールされていない

**解決策:**
```bash
pip install pandas matplotlib seaborn tqdm
```

### 処理が途中で止まる

**原因1:** メモリ不足

**解決策:**
```python
# batch_config.json に追加
{
  ...
  "output_detail_dir": null  # 詳細レポートを無効化してメモリ節約
}
```

**原因2:** GPU メモリ不足

**解決策:**
```bash
# 環境変数でバッチサイズを制限
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
python batch_analyzer.py batch_config.json
```

### CSVがExcelで文字化け

**原因:** UTF-8非対応のExcelバージョン

**解決策:**
- 既に UTF-8 BOM 付きで保存されているので、最新のExcelなら開けるはず
- それでもダメなら：
  1. Excelで「データ」→「テキストファイル」から開く
  2. エンコードを「UTF-8」に指定

### 統計分析が実行できない

**原因:** CSVのパスが間違っている

**解決策:**
```bash
# 正しいパスを確認
ls -la results/batch_analysis.csv

# 絶対パスで指定
python analyze_results.py /full/path/to/results/batch_analysis.csv
```

---

## まとめ

### このシステムでできること

1. ✅ 300枚の画像を自動で分析（手動なら数日 → 自動で30分）
2. ✅ 統計的に根拠のある閾値を決定（勘ではなくデータ駆動）
3. ✅ ハルシネーション（AIの偽ディテール）を検出
4. ✅ モデル間の性能比較
5. ✅ 医療画像の品質基準を確立

### 次のステップ

1. **300枚のデータで実験** → `batch_analyzer.py`
2. **統計分析で閾値決定** → `analyze_results.py`
3. **閾値をアプリに実装** → 医療画像モード追加
4. **論文執筆** → N=300の根拠あるデータとして引用可能

### 参考資料

- **NIH ChestX-ray14**: https://nihcc.app.box.com/v/ChestXray-NIHCC
- **PSNR/SSIM の理論**: Wang et al. "Image Quality Assessment" (IEEE TIP 2004)
- **医療画像AI**: FDA Guidance on AI/ML-Based Medical Devices

---

**質問・サポート:**
- GitHubで Issue を作成
- README.md も参照

**ライセンス:** MIT License
