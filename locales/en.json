{
  "app": {
    "title": "AI Image Analyzer Pro",
    "version": "v1.7.0 - Multilingual Edition",
    "subtitle": "Medical AI Quality Assessment ‚Ä¢ Academic Paper Support ‚Ä¢ 26-Pattern Anomaly Detection"
  },
  "tabs": {
    "single_analysis": "Single Image Analysis",
    "batch_processing": "Batch Processing",
    "academic_benchmark": "Academic Benchmark Evaluation"
  },
  "modes": {
    "image": "Image (X-ray, Endoscopy, Photos, etc.)",
    "document": "Document (Medical Records, Contracts, Receipts, etc.)",
    "academic": "Academic Evaluation Mode",
    "developer": "Developer Mode (Bug Testing & Debugging)",
    "image_desc": "‚îî‚îÄ CLIP Threshold: 0.70, All metrics, Auto-detect diagnostic text",
    "document_desc": "‚îî‚îÄ CLIP Threshold: 0.90 (Strict), Text MAE focused",
    "developer_desc": "‚îî‚îÄ Full metric details, Processing time measurement"
  },
  "buttons": {
    "browse": "Browse",
    "analyze": "Start Analysis",
    "analyze_batch": "Start Batch Processing",
    "analyze_academic": "Start Academic Benchmark Evaluation",
    "analyze_stats": "Start Statistical Analysis (Generate 25 Plots)",
    "export_csv": "Export CSV",
    "export_report": "Export Detailed Report",
    "language": "Language"
  },
  "labels": {
    "original_image": "Original Image (Ground Truth)",
    "upscaled_image": "Upscaled Image (AI Result)",
    "output_folder": "Output Folder",
    "original_folder": "Original Image Folder (GT Images)",
    "model_folder": "Super-Resolution Model Folder",
    "model_name": "Model Name",
    "csv_output": "Output CSV File",
    "detail_output": "Detailed Report Output",
    "limit": "Sample Limit (0=All)",
    "append_mode": "Append Mode (Add to existing CSV)",
    "evaluation_mode": "Evaluation Mode"
  },
  "sections": {
    "original_image_required": "üéØ Original Image (Required ‚Ä¢ GT Image)",
    "upscaled_images": "üîç Upscaled Images (Comparison ‚Ä¢ Max 5)",
    "upscaled_image_1": "üì∏ Image 1 (AI Result)",
    "upscaled_image_2": "üì∏ Image 2 (AI Result ‚Ä¢ Optional)",
    "upscaled_image_3": "üì∏ Image 3 (AI Result ‚Ä¢ Optional)",
    "upscaled_image_4": "üì∏ Image 4 (AI Result ‚Ä¢ Optional)",
    "upscaled_image_5": "üì∏ Image 5 (AI Result ‚Ä¢ Optional)",
    "output_folder": "üíæ Output Folder",
    "evaluation_settings": "‚öôÔ∏è Evaluation Settings",
    "folder_settings": "üìÅ Folder Settings",
    "csv_settings": "üíæ CSV Output Settings",
    "detail_output": "üìÑ Detailed Report Output",
    "stats_analysis": "üìä Statistical Analysis & Plot Generation",
    "bicubic_info": "üîç About Bicubic Downscaling"
  },
  "warnings": {
    "png_recommended": "‚ö†Ô∏è PNG format recommended (JPEG is lossy and already degraded)"
  },
  "gui": {
    "patch_size_title": "P6 Heatmap Precision (Patch Size):",
    "patch_8x8": "8√ó8 - Ultra-high precision (medical images, paper quality)",
    "patch_8x8_detail": "  16,384 blocks (1024√ó1024 image) - Most detailed analysis",
    "patch_16x16": "16√ó16 - Standard precision (paper standard) ‚≠ê Recommended",
    "patch_16x16_detail": "  4,096 blocks (1024√ó1024 image) - Balance of precision and speed",
    "patch_32x32": "32√ó32 - High speed",
    "patch_32x32_detail": "  1,024 blocks (1024√ó1024 image) - Quick overview",
    "original_note": "‚Äª High-resolution original image before AI processing (before super-resolution, noise removal, etc.)\n‚Äª Evaluate accuracy by comparing each AI result (Image 1-5) with this original image",
    "placeholder_select_original": "Please select original image (required)...",
    "placeholder_select_image": "Select image file...",
    "status_start": "Please select images and start analysis",
    "report_button": "[STATS] Report",
    "folder_button": "[FOLDER] Folder",
    "clear_button": "[CLR] Clear",
    "preview_title": "[IMG] Image Comparison Preview",
    "original_before": "[FILE] Original Image (Before)",
    "select_original_prompt": "Please select original image",
    "sr_result_1": "[SR] Super-Resolution Result 1 (After)",
    "select_sr1_prompt": "Please select super-resolution result 1",
    "sr_result_2": "[SR] Super-Resolution Result 2 (After)",
    "select_sr2_prompt": "Please select super-resolution result 2",
    "interpretation_title": "[STATS] Easy Interpretation",
    "detailed_log_title": "[LOG] Detailed Data",
    "batch_progress_title": "[STATS] Batch Processing Progress",
    "batch_start_prompt": "Please start batch processing",
    "batch_log_title": "[LOG] Processing Result Log",
    "academic_progress_title": "[STATS] Academic Benchmark Evaluation Progress",
    "academic_start_prompt": "Please start academic evaluation (recommended: 15,000 images)",
    "academic_log_title": "[LOG] Processing Result Log",
    "select_image_1": "Select Image 1",
    "select_image_2": "Select Image 2",
    "select_image_3": "Select Image 3",
    "select_image_4": "Select Image 4",
    "select_image_5": "Select Image 5",
    "select_original_before": "Select Original Image (Before Processing/Before)",
    "select_output_folder": "Select Output Folder",
    "image_load_error": "Image loading error:\n{error}",
    "error_select_original": "Please select the original image (GT image)",
    "error_original_not_found": "Original image not found:\n{path}",
    "error_select_image1": "Please select at least Image 1 (AI processing result)",
    "error_image1_not_found": "Image 1 not found:\n{path}",
    "error_image_not_found": "Image {num} not found:\n{path}",
    "status_analyzing": "Analyzing: {step}",
    "status_analysis_complete": "[OK] Accuracy evaluation - {count} items completed",
    "status_complete": "[OK] Analysis complete",
    "status_error": "[ERROR] An error occurred",
    "error_analysis_failed": "An error occurred during analysis:\n{error}",
    "warning_output_not_found": "Output folder not found:\n{path}",
    "status_cleared": "Results cleared",
    "warning_no_report": "Comparison report not found.\nPlease run analysis first.",
    "lang_japanese": "üáØüáµ Êó•Êú¨Ë™û",
    "complete_title": "Complete",
    "error_title": "Error",
    "warning_title": "Warning",
    "analysis_complete_multi_message": "Accuracy evaluation completed.\n{count} comparisons completed.\n\nResults saved to '{folder}' folder.",
    "analysis_complete_single_message": "Analysis completed.\n\nResults saved to '{folder}' folder.\n\nYou can check the comparison results in the \"[STATS] Interpretation\" tab.",
    "comparison_report_title": "Comparison Report",
    "accuracy_eval_header": "=== Accuracy Evaluation (Original vs AI Result) - {count} Comparisons ===\n\n",
    "error_prefix": "Error:\n{error}"
  },
  "batch": {
    "title": "[BATCH] About Batch Processing",
    "description": "Automatically analyze large numbers of image pairs (300+ images) and determine statistically valid thresholds.\nIdeal for medical image research and AI model comparison.",
    "original_folder_label": "[FOLDER] Original Image Folder (Required ‚Ä¢ Before processing ‚Ä¢ PNG recommended)",
    "model_folder_label": "[MODEL] Super-Resolution Model Folders (Required ‚Ä¢ Min 1, Max 5)",
    "model_name_placeholder": "Model {num} Name",
    "detail_label": "Detail:",
    "append_mode_label": "Append data to existing CSV (unchecked = overwrite mode)",
    "limit_note": "‚Äª 0 = process all images, 10 = process first 10 only (for testing)",
    "limit_label": "Sample Limit:",
    "limit_all": "All",
    "limit_direct_input": "Direct input (for large batches):",
    "limit_placeholder": "0 = process all",
    "parallel_info": "[PARALLEL] Parallel Processing Settings (Effective for 1000+ images; slower for small batches)",
    "use_parallel": "Use Parallel Processing",
    "num_workers": "Number of Processes:",
    "workers_hint": "(Recommended: {recommended}, Max: {max})",
    "patch_size_title": "P6 Heatmap Precision (Patch Size):",
    "patch_size_desc": "For large batches, 16√ó16 (standard) is recommended; for medical images, select 8√ó8",
    "patch_8x8": "8√ó8 (Ultra-high precision, for medical images)",
    "patch_16x16": "16√ó16 (Standard precision, paper standard) ‚≠ê Recommended",
    "patch_32x32": "32√ó32 (High speed, quick overview)",
    "stats_desc": "After batch processing, statistically analyze the CSV file to generate 25 types of research plots.",
    "csv_placeholder": "Select results/batch_analysis.csv...",
    "csv_select_button": "[FOLDER] Select CSV",
    "hallucination_warning": "[WARNING] Extract Suspected Hallucination Data",
    "normal_data_extract": "[EXTRACT] Extract Normal Data (for AI Training)",
    "export_log": "[EXPORT] Save Log to File",
    "select_original_folder": "Select Original Image Folder",
    "select_model_folder": "Select Model {num} Folder",
    "select_csv_output": "Select CSV Output Destination",
    "select_detail_folder": "Select Detailed Report Output Folder",
    "error_no_input": "Please select input folder",
    "error_input_not_found": "Input folder not found:\n{path}",
    "error_no_output": "Please select output folder",
    "error_invalid_scale": "Please specify a downscale factor greater than 0 and less than 1",
    "error_scale_not_number": "Please specify downscale factor as a number",
    "error_no_images": "No image files found in input folder:\n{path}",
    "bicubic_complete": "Complete",
    "error_bicubic_failed": "An error occurred during batch processing:\n{error}",
    "error_no_original_folder": "Please select the original image folder (GT images)",
    "error_original_folder_not_found": "Original image folder not found:\n{path}",
    "error_no_model_name": "Please enter name for Model {num}",
    "error_model_not_found": "Model {num} folder not found:\n{path}",
    "error_no_models": "Please select at least one super-resolution model folder (AI processing results)",
    "status_starting": "Starting batch processing...",
    "status_processing": "Processing: {current}/{total} - {message}",
    "status_complete": "[OK] Batch processing complete! CSV file: {path}",
    "status_error": "[ERROR] Batch processing error",
    "error_batch_failed": "An error occurred during batch processing:\n{output}",
    "limit_display_all": "All",
    "limit_display_count": "{count} images"
  },
  "batch_analyzer": {
    "warning_jpg_detected": "[WARNING] JPEG files detected ({count} images)",
    "jpg_lossy_warning": "JPEG is a lossy compression format and image quality is already degraded.",
    "jpg_recommend_png": "For accurate evaluation, strongly recommend re-exporting from original data in PNG format.",
    "jpg_problems_title": "„ÄêJPEG Issues„Äë",
    "jpg_problem_1": "  - Block noise (8√ó8 pixel compression artifacts)",
    "jpg_problem_2": "  - Loss of high-frequency components (fine details lost)",
    "jpg_problem_3": "  - Color information degradation (color bleeding, banding)",
    "jpg_problem_4": "  - Indistinguishable from AI super-resolution degradation",
    "jpg_recommended_actions": "„ÄêRecommended Actions„Äë",
    "jpg_action_1": "  1. Re-export in PNG format from original software/camera",
    "jpg_action_2": "  2. Convert from lossless formats like TIFF",
    "jpg_action_3": "  3. Always use PNG format for medical use and paper publication",
    "info_limit_mode": "[INFO] Split execution mode: Processing only first {limit} images",
    "error_original_not_found": "[ERROR] Original images not found: {path}",
    "original_dir": "Original image directory: {path}",
    "original_count": "Original image count: {count} images",
    "model_count": "Super-resolution model count: {count} types",
    "output_csv": "Output CSV: {path}",
    "parallel_workers": "Parallel processing: {workers} processes",
    "checkpoint_interval": "Checkpoint interval: every {interval} samples",
    "warning_upscaled_jpg": "[WARNING] JPEG files detected in super-resolution results",
    "model_jpg_count": "  - {model}: {count} JPEG files",
    "jpg_cannot_evaluate": "JPEG lossy compression prevents accurate AI processing quality evaluation.",
    "jpg_recommend_reexport": "Strongly recommend re-exporting in PNG format from original AI super-resolution tool.",
    "checkpoint_saving": "[INFO] Saving checkpoint... ({current}/{total})",
    "elapsed_time": "  Elapsed time: {minutes} minutes",
    "remaining_time": "  Remaining time: {minutes} minutes",
    "success_error_count": "  Success: {success}, Errors: {errors}",
    "success_total": "  Success: {success} / {total}",
    "error_total": "  Errors: {errors} / {total}",
    "total_time": "  Total processing time: {minutes} minutes ({hours} hours)",
    "avg_time": "  Average processing speed: {seconds} sec/sample",
    "parallel_efficiency": "  Parallelization efficiency: {workers} processes used",
    "model_counts": "\nModel-wise processing counts:",
    "model_count_item": "   {model}: {count} items",
    "result_csv": "\nResult CSV: {path}",
    "detail_report": "Detailed report: {path}",
    "checkpoint_file": "Checkpoint: {path}",
    "checkpoint_deleted": "\n[INFO] Checkpoint file deleted (normal completion)",
    "error_no_images": "\n[ERROR] No processable images found",
    "append_mode_saving": "\n[INFO] Saving in append mode...",
    "existing_data": "   Existing data: {count} rows",
    "new_data": "   New data: {count} rows",
    "combined_data": "   After combining: {count} rows",
    "file_path": "   File: {path}",
    "unique_images": "   Images: {count}",
    "unique_models": "   Models: {count}",
    "append_mode_create": "\n[INFO] Append mode but no existing CSV, creating new file",
    "overwrite_mode": "\n[INFO] Saving in overwrite mode...",
    "total_rows": "   Total rows: {count}",
    "model_avg_scores": "\nModel-wise average scores:",
    "overall_ranking": "Overall score ranking:",
    "rank_item": "   {rank}. {model:20s} - {score:.2f} points",
    "mapping_csv_generating": "[INFO] Generating image pair mapping table...",
    "mapping_csv_complete": "[OK] Mapping CSV generation complete: {name}",
    "mapping_total_pairs": "  Total pairs: {count}",
    "mapping_matched": "  Matched: {count}",
    "mapping_unmatched": "  Unmatched: {count}",
    "mapping_warning_unmatched": "  [WARNING] Unmatched images found. Please check CSV and manually correct.",
    "mapping_using_existing": "[INFO] Using existing mapping CSV",
    "mapping_csv_generated": "[INFO] Mapping CSV has been generated.",
    "user_cancelled": "\n[INFO] Batch processing cancelled by user.",
    "config_not_found": "[ERROR] Config file not found: {config_file}",
    "config_template_created": "\n[OK] Config template created successfully: {config_path}",
    "mapping_dialog_title": "Mapping CSV Confirmation",
    "mapping_dialog_message": "Image pair mapping CSV has been auto-generated.\n\nMatched: {matched} pairs\nUnmatched: {unmatched} pairs\n\n{warning}Do you want to review the mapping table?\n\n[Yes] ‚Üí Open CSV for review\n[No] ‚Üí Continue analysis as-is\n[Cancel] ‚Üí Abort processing",
    "mapping_dialog_warning": "‚ö†Ô∏è Unmatched images found!\n\n",
    "mapping_proceed_title": "Continue Confirmation",
    "mapping_proceed_message": "Mapping CSV has been reviewed.\n\nContinue with analysis?\n\n‚ÄªIf you modified the mapping results,\n  please save as results/mapping.csv.",
    "mapping_error_title": "Error",
    "mapping_error_message": "Failed to open CSV file: {error}",
    "eval_mode_image": "Image mode (medical images, photos, etc.)",
    "eval_mode_document": "Document mode (medical records, contracts, etc.)",
    "eval_mode_academic": "Academic evaluation mode (paper publication, standard benchmarks)",
    "eval_mode_developer": "Developer mode (debugging)",
    "task_count": "Processing tasks: {count}",
    "estimated_time": "Estimated time: {time:.1f} min (15 sec/sample)",
    "parallel_start": "Starting parallel processing with {workers} processes...",
    "task_completed": "Completed: {image_id} - {model}",
    "progress_desc": "Batch processing",
    "csv_file_label": "   File: {path}",
    "csv_image_count": "   Images: {count}",
    "csv_model_count": "   Models: {count}",
    "csv_total_rows": "   Total rows: {count}"
  },
  "metrics": {
    "ssim": "SSIM (Structural Similarity)",
    "ms_ssim": "MS-SSIM (Multi-Scale)",
    "psnr": "PSNR (Peak Signal-to-Noise Ratio)",
    "lpips": "LPIPS (Learned Perceptual Image Patch Similarity)",
    "sharpness": "Sharpness",
    "contrast": "Contrast",
    "entropy": "Entropy (Information Content)",
    "noise": "Noise Level",
    "edge_density": "Edge Density",
    "artifacts": "Artifacts",
    "delta_e": "Color Difference (ŒîE)",
    "high_freq_ratio": "High Frequency Ratio",
    "texture_complexity": "Texture Complexity",
    "local_quality": "Local Quality",
    "histogram_corr": "Histogram Correlation",
    "lab_L_mean": "LAB Lightness",
    "total_score": "Total Score"
  },
  "messages": {
    "select_image": "Please select an image",
    "select_folder": "Please select a folder",
    "processing": "Processing: {current}/{total}",
    "completed": "‚úÖ Processing completed",
    "error": "‚ùå An error occurred",
    "file_not_found": "File not found: {path}",
    "batch_start": "üöÄ Batch processing started",
    "batch_complete": "‚úÖ Batch processing completed!",
    "checkpoint_saved": "üíæ Checkpoint saved: {count} samples",
    "eta": "‚è±Ô∏è Time remaining: {minutes} min",
    "parallel_processing": "‚ö° Parallel processes: {workers}"
  },
  "errors": {
    "invalid_path": "Invalid path",
    "no_models": "Please select at least one model folder",
    "analysis_failed": "Analysis failed: {error}"
  },
  "stats": {
    "model_comparison": "Average Scores by Model",
    "total_samples": "Total Samples",
    "success_rate": "Success Rate",
    "average_score": "Average Score",
    "ranking": "üèÜ Overall Score Ranking"
  },
  "patterns": {
    "P1": "P1: High SSIM √ó Low PSNR (Structure preserved, frequency loss)",
    "P2": "P2: High Sharpness √ó High Noise (Over-sharpening)",
    "P3": "P3: High Edge √ó Low Quality (Edge enhancement, internal degradation)",
    "P4": "P4: High Artifacts (Ringing, block noise)",
    "P5": "P5: High Freq √ó Low Texture (False detail generation)",
    "P6": "P6: High Quality Variance (Localized processing failure)",
    "P7": "P7: Low Entropy √ó High Freq (Information deficit)",
    "P8": "P8: Abnormal Contrast √ó Low Hist Corr (Color distortion)",
    "P9": "P9: Low MS-SSIM √ó Low Total (Multi-scale degradation)"
  },
  "help": {
    "workflow_title": "üìñ Correct Evaluation Workflow",
    "workflow_step1": "1. Downscale original (GT: 1000√ó1000px) by 0.5√ó using bicubic",
    "workflow_step2": "2. Upscale downscaled image (LR: 500√ó500px) by 2√ó using AI SR",
    "workflow_step3": "3. Compare SR result (SR: 1000√ó1000px) with original (GT)",
    "common_mistake": "‚ùå Common mistake: Setting downscaled as GT and original as SR"
  },
  "academic": {
    "title": "[ACAD] About Academic Benchmark Evaluation",
    "description": "Create reference images with standard bicubic downscaling for fair comparison with existing research.\nEvaluate super-resolution models quantitatively on large datasets (15,000 images recommended) and generate data for paper submission.",
    "workflow_steps": "Step 1: Prepare high-resolution images (15,000 recommended)\nStep 2: Configure original image and SR model folders\nStep 3: Start batch processing (several hours to 1 day)\nStep 4: Generate statistics analysis and 25 plots ‚≠ê Required\nStep 5: Check detection_count (26 patterns) ‚Üí Use for deep learning",
    "bicubic_desc": "Batch generate low-resolution LR images from high-resolution GT images (for √ó2 SR evaluation).\nSkippable if you already have LR images.",
    "input_folder_label": "Input Folder (High-res GT, e.g., 1000px √ó 15,000 images):",
    "output_folder_label": "Output Folder (Low-res LR, e.g., 500px √ó 15,000 images):",
    "scale_label": "Downscale Factor:",
    "scale_note": "(0.5 = for √ó2 SR, 0.25 = for √ó4 SR)",
    "run_bicubic": "[BATCH] Run Batch Bicubic Downscaling",
    "mode_info": "[STATS] Evaluation Mode: Academic Evaluation Mode (Bicubic downscaling, √ó2 scale standard evaluation)",
    "original_folder_required": "[FOLDER] Original Image Folder (Required ‚Ä¢ High-res images ‚Ä¢ PNG recommended)",
    "model_folder_label": "[MODEL] Super-Resolution Model Folders (Required ‚Ä¢ Min 1, Max 5)",
    "model_name_placeholder": "Model {num} Name",
    "model_path_placeholder": "dataset/model{num}/",
    "save_settings": "[SAVE] Output Settings",
    "csv_label": "CSV:",
    "detail_label": "Detail:",
    "processing_limit": "[STATS] Processing Limit:",
    "limit_hint": "(0=all images, 15,000 recommended for papers)",
    "append_mode_label": "Append to existing CSV (checked=append, unchecked=overwrite)",
    "parallel_info": "[PARALLEL] Parallel Processing Settings (Recommended for 15,000 images; slower for small batches)",
    "use_parallel": "Use Parallel Processing",
    "num_workers": "Number of Processes:",
    "workers_hint": "(Recommended: {recommended}, Max: {max})",
    "patch_size_title": "P6 Heatmap Precision (Patch Size):",
    "patch_size_desc": "For paper quality, 16√ó16 (standard) or 8√ó8 (ultra-high precision) recommended",
    "patch_8x8": "8√ó8 (Ultra-high precision, for medical images and top-quality papers)",
    "patch_16x16": "16√ó16 (Standard precision, paper standard) ‚≠ê Recommended",
    "patch_32x32": "32√ó32 (Fast, for overview)",
    "stats_warning": "[WARNING] After batch processing, you MUST run this statistical analysis.\n26-pattern hallucination detection and detection_count will be generated.\nThis detection_count becomes the label for deep learning!",
    "select_gt_folder": "Select High-Resolution GT Image Folder",
    "select_lr_folder": "Select Low-Resolution LR Output Folder",
    "select_original_folder": "Select Original Image Folder (High-res images, 15,000 recommended)",
    "select_model_folder": "Select Super-Resolution Model {num} Folder",
    "select_csv_output": "Select CSV Output Destination",
    "select_detail_folder": "Select Detailed Report Output Folder",
    "select_stats_csv": "Select CSV File for Statistical Analysis",
    "error_no_original": "Please select the original image folder (GT images)",
    "error_original_not_found": "Original image folder not found:\n{path}",
    "error_no_model_name": "Please enter name for Model {num}",
    "error_model_not_found": "Model {num} folder not found:\n{path}",
    "error_no_models": "Please select at least one super-resolution model folder (AI processing results)",
    "starting_evaluation": "Starting academic benchmark evaluation...",
    "evaluation_complete": "[OK] Evaluation complete! Next, run statistical analysis",
    "evaluation_complete_detail": "Academic benchmark evaluation completed.\n\nCSV: {csv_path}\n\n‚≠ê Next, you MUST run statistical analysis!\n26-pattern detection and detection_count will be generated.",
    "evaluation_error": "[ERROR] Evaluation Error",
    "stats_running": "Running statistical analysis and 26-pattern detection...",
    "stats_complete": "[OK] Statistical analysis complete! detection_count has been generated",
    "stats_complete_detail": "Statistical analysis completed.\n\n[OK] 25 types of plots generated\n[OK] 26-pattern hallucination detection complete\n[OK] detection_count added to CSV\n\nOutput: analysis_output/\n\nNext Step:\nCheck results_with_26pattern_detection.csv,\nand use detection_count to generate labels for deep learning.",
    "stats_error": "[ERROR] Statistical Analysis Error",
    "error_no_stats_csv": "Please select a CSV file",
    "error_stats_csv_not_found": "CSV file not found:\n{path}",
    "placeholder_gt_folder": "Select GT image folder...",
    "placeholder_lr_folder": "Select LR image output folder...",
    "placeholder_original": "dataset/original/",
    "placeholder_stats_csv": "batch_results_academic.csv",
    "error_select_original_first": "Please select the original image first",
    "error_original_file_not_found": "Original image file not found:\n{path}",
    "error_image_load_failed": "Failed to load image",
    "bicubic_complete_title": "Generation Complete",
    "bicubic_complete_message": "[OK] Low-resolution image generated successfully\n\nOriginal: {w}√ó{h}px\nGenerated: {w_lr}√ó{h_lr}px (√ó0.5 Bicubic)\n\nSaved to:\n{output_path}\n\nNext Steps:\n1. Upscale this LR image using external AI SR tool\n2. Select SR results as Image 1/2\n3. Use currently selected image as GT\n4. Set evaluation mode to 'Academic Evaluation Mode'\n5. Run analysis",
    "error_bicubic_failed": "Failed to generate low-resolution image:\n{error}"
  },
  "analyzer": {
    "separator": "================================================================================",
    "separator_short": "============================================================",
    "mode_academic": "[Analysis Pattern] Academic Evaluation Mode",
    "mode_evaluation": "[Analysis Pattern] Quality Evaluation Mode (Based on Original Image)",
    "usage_academic": " Purpose: Quantitative evaluation for academic papers (PSNR/SSIM/LPIPS, etc.)",
    "usage_evaluation": " Purpose: Accuracy evaluation of AI super-resolution, image enhancement, denoising, etc.",
    "comparison_academic": "   Comparison target: Quantitative comparison with DIV2K, Set5, Set14, etc.",
    "comparison_evaluation": " Comparison target: Original image (Before) vs AI super-resolution result (After)",
    "image_size_academic": "   Original image: {w}x{h}px",
    "image_size_evaluation": "   Original image: {w}x{h}px",
    "ai_result_size": "   AI processing result: {w}x{h}px",
    "report_title": "Detailed Image Comparison Analysis Report",
    "section_1": "[1. Basic Information]",
    "section_2": "[2. Structural Similarity (SSIM)]",
    "section_2_5": "[2.5. MS-SSIM (Multi-Scale SSIM)]",
    "section_3": "[3. PSNR (Peak Signal-to-Noise Ratio)]",
    "section_3_4": "[3.4. Pixel Difference (MAE)]",
    "section_3_5": "[3.5. LPIPS (Learned Perceptual Image Patch Similarity)]",
    "section_10": "[10. Color Distribution Analysis (RGB/HSV/LAB)]",
    "section_11": "[11. Frequency Domain Analysis (FFT)]",
    "section_12": "[12. Texture Analysis]",
    "section_13": "[13. Local Quality Analysis (Patch-based SSIM)]",
    "section_13_1": "[13.1 P6 Heatmap Generation (Local Quality Variation)]",
    "section_13_2": "[13.2 Interactive HTML Heatmap Generation]",
    "section_13_3": "[13.3 Raw Data Output in CSV Format]",
    "section_14": "[14. Histogram Similarity]",
    "section_15": "[15. Overall Evaluation Score]",
    "section_16": "[16. Generating result visualizations...]",
    "system_usage": "\n[{stage}] System usage:",
    "cpu_usage": "  CPU: {percent:.1f}% ({count} cores)",
    "ram_usage": "  RAM: {percent:.1f}% ({used:.1f}/{total:.1f} GB)",
    "gpu_usage": "  GPU: {percent:.1f}% in use",
    "gpu_unused": "  GPU: Unused (CPU processing)",
    "vram_usage": "  VRAM: {percent:.1f}% ({used:.0f}/{total:.0f} MB)",
    "gpu_temp": "  GPU temperature: {temp}¬∞C",
    "result_size_1": "SR result 1 size: {w} x {h} px",
    "result_size_2": "SR result 2 size: {w} x {h} px",
    "filesize_1": "SR result 1 file size: {size:.2f} MB",
    "filesize_2": "SR result 2 file size: {size:.2f} MB",
    "filesize_diff": "Size difference: {diff:.2f} MB ({percent:+.1f}%)",
    "original_filesize": "Original image (before) file size: {size:.2f} MB",
    "device_info": "\nCompute device information:",
    "gpu_name": "  GPU: {name}",
    "gpu_none": "  GPU: None (using CPU)",
    "cuda_available_yes": "  CUDA available: Yes",
    "cuda_available_no": "  CUDA available: No",
    "vram_size": "  VRAM size: {size:.1f} GB",
    "pytorch_not_installed": "  PyTorch not installed (GPU features disabled)",
    "ssim_description": "1.0 = perfect match, 0.0 = completely different",
    "gpu_processing": "[GPU processing] Device: {device}",
    "ssim_vs_original": "SR image vs original SSIM: {value:.4f}",
    "eval_ssim_excellent": "  Evaluation: [OK] Excellent (SSIM ‚â• 0.95: nearly identical to original)",
    "eval_ssim_good": "  Evaluation: [OK] High quality (SSIM ‚â• 0.85: meets criteria)",
    "eval_ssim_acceptable": "  Evaluation: [WARNING] Acceptable (SSIM 0.70-0.85: slightly lower)",
    "eval_ssim_poor": "  Evaluation: [ERROR] Low quality (SSIM < 0.70: below criteria)",
    "ms_ssim_description": "Multi-scale structural similarity (closer to 1.0 = more similar)",
    "ms_ssim_value": "MS-SSIM: {value:.4f}",
    "eval_ms_ssim_perfect": "  Evaluation: Nearly perfect match",
    "eval_ms_ssim_very_similar": "  Evaluation: Very similar",
    "eval_ms_ssim_similar": "  Evaluation: Similar",
    "eval_ms_ssim_somewhat": "  Evaluation: Somewhat similar",
    "eval_ms_ssim_different": "  Evaluation: Different",
    "psnr_description": "Higher values indicate similarity (30dB+ = visually nearly identical)",
    "psnr_vs_original": "SR image vs original PSNR: {value:.2f} dB",
    "eval_psnr_excellent": "  Evaluation: [OK] Excellent (PSNR ‚â• 40 dB: very high quality)",
    "eval_psnr_good": "  Evaluation: [OK] High quality (PSNR ‚â• 35 dB: meets criteria)",
    "eval_psnr_acceptable": "  Evaluation: [WARNING] Acceptable (PSNR ‚â• 30 dB: visually nearly identical)",
    "eval_psnr_poor": "  Evaluation: [ERROR] Low quality (PSNR < 30 dB: below criteria)",
    "mae_description": "Mean absolute error per pixel vs original (lower = closer, 0 = perfect match)",
    "mae_overall": " Overall MAE:",
    "mae_vs_original": "  SR image vs original: {value:.2f} (difference rate: {ratio:.1f}%)",
    "eval_mae_excellent": "  Evaluation: [OK] Excellent (MAE < 2: nearly perfect match)",
    "eval_mae_good": "  Evaluation: [OK] High quality (MAE < 5: meets criteria)",
    "eval_mae_acceptable": "  Evaluation: [WARNING] Acceptable (MAE < 10: some difference)",
    "eval_mae_poor": "  Evaluation: [ERROR] Low quality (MAE ‚â• 10: below criteria)",
    "mae_text_region": " Text region MAE (excluding white background, {percent:.1f}% of area):",
    "eval_text_mae_excellent": "  Evaluation: [OK] Excellent (Text MAE < 2: nearly perfect match)",
    "eval_text_mae_good": "  Evaluation: [OK] High quality (Text MAE < 5: meets criteria)",
    "eval_text_mae_acceptable": "  Evaluation: [WARNING] Acceptable (Text MAE < 10: some difference)",
    "eval_text_mae_poor": "  Evaluation: [ERROR] Low quality (Text MAE ‚â• 10: below criteria)",
    "lpips_description": "Deep learning-based perceptual similarity (closer to 0 = more similar)",
    "lpips_value": "LPIPS: {value:.4f}",
    "lpips_gpu_usage": "  GPU used: {used} (memory usage: {percent:.1f}%)",
    "eval_lpips_perfect": "  Evaluation: Nearly perfect match",
    "eval_lpips_very_similar": "  Evaluation: Very similar",
    "eval_lpips_similar": "  Evaluation: Perceptually similar",
    "eval_lpips_somewhat": "  Evaluation: Somewhat different",
    "eval_lpips_different": "  Evaluation: Significantly different",
    "psnr_calc_start_gpu": "Starting PSNR calculation (GPU)",
    "psnr_calc_start_cpu": "Starting PSNR calculation (CPU)",
    "mae_overall_header": " Overall MAE:",
    "mae_text_header": "\n Text region MAE (excluding white background, {ratio:.1f}% of area):",
    "mae_text_vs_original": "  SR image vs original: {value:.2f} (difference ratio: {ratio:.1f}%)",
    "eval_mae_text_excellent": "  Evaluation: [OK] Excellent (text MAE < 2: nearly perfect match)",
    "eval_mae_text_good": "  Evaluation: [OK] High quality (text MAE < 5: meets criteria)",
    "eval_mae_text_acceptable": "  Evaluation: [WARNING] Acceptable (text MAE < 10: some differences)",
    "eval_mae_text_poor": "  Evaluation: [ERROR] Low quality (text MAE ‚â• 10: below criteria)",
    "mae_text_not_detected": "\n  [WARNING]  No text regions detected (image contains only white background)",
    "lpips_calc_start": "Starting LPIPS calculation",
    "lpips_calc_complete": "LPIPS calculation complete",
    "lpips_gpu_yes_mem": "  GPU used: Yes (memory usage: {usage:.1f}%)",
    "lpips_gpu_yes": "  GPU used: Yes",
    "lpips_gpu_no": "  GPU used: No (CPU processing)",
    "eval_lpips_nearly_identical": "  Evaluation: Perceptually nearly identical",
    "eval_lpips_somewhat_different": "  Evaluation: Somewhat different",
    "eval_lpips_very_different": "  Evaluation: Significantly different",
    "lpips_skipped": "  ‚ÄªLPIPS calculation skipped (library not installed)",
    "section_3_6": "\n„Äê3.6. CLIP Embeddings (Semantic Similarity)„Äë",
    "clip_description": "Semantic similarity by OpenAI CLIP model (closer to 1.0 = more semantically similar)",
    "clip_calc_start": "Starting CLIP calculation",
    "clip_calc_complete": "CLIP calculation complete",
    "eval_mode_document": " Evaluation mode: Document mode (strict criteria)",
    "eval_mode_developer": " Evaluation mode: Developer mode (for reference)",
    "doc_image_detected": " Document image auto-detected (document mode recommended)",
    "clip_vs_original": "SR image vs original CLIP: {value:.4f}",
    "clip_gpu_yes": "  GPU used: Yes",
    "clip_gpu_no": "  GPU used: No (CPU processing)",
    "clip_doc_warning": "  [WARNING]  Document/medical image detected: CLIP uses strict criteria",
    "eval_clip_doc_excellent": "  Evaluation: [OK] Excellent (CLIP > 0.98: semantically nearly identical)",
    "eval_clip_doc_good": "  Evaluation: [OK] High quality (CLIP > 0.95: meets criteria, note: documents tend to score high on structural similarity)",
    "eval_clip_doc_acceptable": "  Evaluation: [WARNING] Acceptable (CLIP > 0.90: structure similar but content may differ)",
    "eval_clip_doc_poor": "  Evaluation: [ERROR] Low quality (CLIP ‚â§ 0.90: completely different images)",
    "eval_clip_excellent": "  Evaluation: [OK] Excellent (CLIP > 0.95: semantically nearly identical)",
    "eval_clip_good": "  Evaluation: [OK] High quality (CLIP > 0.85: semantically very similar)",
    "eval_clip_acceptable": "  Evaluation: [WARNING] Acceptable (CLIP > 0.70: semantically similar)",
    "eval_clip_poor": "  Evaluation: [ERROR] Low quality (CLIP ‚â§ 0.70: semantically different)",
    "clip_model_a_vs_orig": "Model A vs original CLIP: {value:.4f}",
    "clip_model_b_vs_orig": "Model B vs original CLIP: {value:.4f}",
    "clip_model_a_closer": "‚Üí Model A is semantically closer to original (+{diff:.4f})",
    "clip_model_b_closer": "‚Üí Model B is semantically closer to original (+{diff:.4f})",
    "clip_eval_doc_nearly_identical": "Semantically nearly identical",
    "clip_eval_doc_similar_warning": "Semantically similar (caution: documents score high on structural similarity)",
    "clip_eval_doc_struct_similar": "[WARNING] Structure similar but content may differ",
    "clip_eval_doc_different": "Completely different images (different content)",
    "clip_eval_nearly_identical": "Semantically nearly identical",
    "clip_eval_very_similar": "Semantically very similar",
    "clip_eval_similar": "Semantically similar",
    "clip_eval_somewhat_similar": "Somewhat similar",
    "clip_eval_different": "Completely different images (different content)",
    "clip_cosine_similarity": "CLIP cosine similarity: {value:.4f}",
    "clip_eval_nearly_identical_img": "  Evaluation: Semantically nearly identical images",
    "clip_eval_similar_warning_img": "  Evaluation: Semantically similar (caution: documents score high on structural similarity)",
    "clip_eval_struct_similar_img": "  Evaluation: [WARNING] Structure similar but content may differ ",
    "clip_eval_different_img": "  Evaluation: Completely different images (different content)",
    "clip_eval_very_similar_img": "  Evaluation: Semantically very similar",
    "clip_eval_similar_img": "  Evaluation: Semantically similar",
    "clip_eval_somewhat_similar_img": "  Evaluation: Somewhat similar",
    "clip_skipped": "  ‚ÄªCLIP calculation skipped (library not installed)",
    "section_4": "\n„Äê4. Sharpness„Äë",
    "sharpness_calc_start_gpu": "Starting sharpness calculation (GPU)",
    "sharpness_calc_start_cpu": "Starting sharpness calculation (CPU)",
    "sharpness_original": "Original image sharpness: {value:.2f}",
    "sharpness_sr": "SR image sharpness: {value:.2f}",
    "sharpness_preservation": "Preservation ratio: {ratio:.2%} ({diff:+.1f}%)",
    "eval_sharpness_excellent": "  Evaluation: [OK] Excellent (sharpness improved: +{improvement:.1f}%)",
    "eval_sharpness_good": "  Evaluation: [OK] High quality (sharpness preserved: {ratio:.2%})",
    "eval_sharpness_acceptable": "  Evaluation: [WARNING] Acceptable (slight degradation: {ratio:.2%})",
    "eval_sharpness_poor": "  Evaluation: [ERROR] Low quality (significant degradation: {ratio:.2%})",
    "sharpness_img1": "Image 1 sharpness: {value:.2f}",
    "sharpness_img2": "Image 2 sharpness: {value:.2f}",
    "sharpness_diff": "Difference: {diff:.2f} ({pct:+.1f}%)",
    "section_5": "\n„Äê5. Contrast„Äë",
    "contrast_original": "Original image contrast: {value:.2f}",
    "contrast_sr": "SR image contrast: {value:.2f}",
    "contrast_preservation": "Preservation ratio: {ratio:.2%} ({diff:+.1f}%)",
    "eval_contrast_excellent": "  Evaluation: [OK] Excellent (contrast improved: +{improvement:.1f}%)",
    "eval_contrast_good": "  Evaluation: [OK] High quality (contrast preserved: {ratio:.2%})",
    "eval_contrast_acceptable": "  Evaluation: [WARNING] Acceptable (slight degradation: {ratio:.2%})",
    "eval_contrast_poor": "  Evaluation: [ERROR] Low quality (significant degradation: {ratio:.2%})",
    "contrast_img1": "Image 1 contrast: {value:.2f}",
    "contrast_img2": "Image 2 contrast: {value:.2f}",
    "contrast_diff": "Difference: {diff:.2f} ({pct:+.1f}%)",
    "section_6": "\n„Äê6. Entropy (Information Content)„Äë",
    "entropy_description": "Higher values indicate more information content (complexity)",
    "entropy_original": "Original image entropy: {value:.3f}",
    "entropy_sr": "SR image entropy: {value:.3f}",
    "entropy_diff": "Difference: {diff:.3f}",
    "entropy_preservation": "Preservation ratio: {ratio:.2%}",
    "eval_entropy_excellent": "  Evaluation: [OK] Excellent (information preserved: {ratio:.2%})",
    "eval_entropy_good": "  Evaluation: [OK] High quality (information mostly preserved: {ratio:.2%})",
    "eval_entropy_acceptable": "  Evaluation: [WARNING] Acceptable (slight change: {ratio:.2%})",
    "eval_entropy_poor": "  Evaluation: [ERROR] Low quality (significant change: {ratio:.2%})",
    "entropy_img1": "Image 1 entropy: {value:.3f}",
    "entropy_img2": "Image 2 entropy: {value:.3f}",
    "section_7": "\n„Äê7. Noise Level Analysis„Äë",
    "noise_calc_start_gpu": "Starting noise estimation (GPU)",
    "noise_calc_start_cpu": "Starting noise estimation (CPU)",
    "noise_original": "Original image noise level: {value:.2f}",
    "noise_sr": "SR image noise level: {value:.2f}",
    "noise_diff": "Difference: {diff:.2f} ({pct:+.1f}%)",
    "eval_noise_excellent": "  Evaluation: [OK] Excellent (noise reduction: -{reduction:.1f}%)",
    "eval_noise_good": "  Evaluation: [OK] High quality (noise maintained: {ratio:.2%})",
    "eval_noise_acceptable": "  Evaluation: [WARNING] Acceptable (slight increase: {ratio:.2%})",
    "eval_noise_poor": "  Evaluation: [ERROR] Low quality (noise increased: +{increase:.1f}%)",
    "noise_img1": "Image 1 noise level: {value:.2f}",
    "noise_img2": "Image 2 noise level: {value:.2f}",
    "section_8": "\n„Äê8. Artifact Detection„Äë",
    "artifact_block_orig": "Original image block noise: {value:.2f}",
    "artifact_block_sr": "SR image block noise: {value:.2f}",
    "artifact_ringing_orig": "Original image ringing: {value:.2f}",
    "artifact_ringing_sr": "SR image ringing: {value:.2f}",
    "eval_artifact_excellent": "  Evaluation: [OK] Excellent (artifact reduction: -{reduction:.1f}%)",
    "eval_artifact_good": "  Evaluation: [OK] High quality (artifacts maintained: {ratio:.2%})",
    "eval_artifact_acceptable": "  Evaluation: [WARNING] Acceptable (slight increase: {ratio:.2%})",
    "eval_artifact_poor": "  Evaluation: [ERROR] Low quality (artifacts increased: +{increase:.1f}%)",
    "artifact_block_img1": "Image 1 block noise: {value:.2f}",
    "artifact_block_img2": "Image 2 block noise: {value:.2f}",
    "artifact_ringing_img1": "Image 1 ringing: {value:.2f}",
    "artifact_ringing_img2": "Image 2 ringing: {value:.2f}",
    "section_9": "\n„Äê9. Edge Preservation„Äë",
    "edge_calc_start_gpu": "Starting edge detection (GPU)",
    "edge_calc_start_cpu": "Starting edge detection (CPU)",
    "edge_density_original": "Original image edge density: {value:.2f}%",
    "edge_density_sr": "SR image edge density: {value:.2f}%",
    "edge_preservation": "Preservation ratio: {ratio:.2%} ({diff:+.1f}%)",
    "eval_edge_excellent": "  Evaluation: [OK] Excellent (edge improvement: +{improvement:.1f}%)",
    "eval_edge_good": "  Evaluation: [OK] High quality (edges preserved: {ratio:.2%})",
    "eval_edge_acceptable": "  Evaluation: [WARNING] Acceptable (slight degradation: {ratio:.2%})",
    "eval_edge_poor": "  Evaluation: [ERROR] Low quality (significant degradation: {ratio:.2%})",
    "edge_density_img1": "Image 1 edge density: {value:.2f}%",
    "edge_density_img2": "Image 2 edge density: {value:.2f}%",
    "edge_diff": "Difference: {diff:.2f}% ({pct:+.1f}%)",
    "section_10": "\n„Äê10. Color Distribution Analysis (RGB/HSV/LAB)„Äë",
    "rgb_colorspace": "RGB Color Space:",
    "channel_red": "  Red Channel:",
    "channel_green": "  Green Channel:",
    "channel_blue": "  Blue Channel:",
    "channel_original": "    Original: Mean={mean:.1f}, Std={std:.1f}",
    "channel_sr": "    AI Result: Mean={mean:.1f}, Std={std:.1f}",
    "hsv_saturation": "\nHSV Color Space - Saturation:",
    "hsv_saturation_original": "  Original: Mean={mean:.1f}",
    "hsv_saturation_sr": "  AI Result: Mean={mean:.1f}",
    "lab_colorspace": "\nLAB Color Space (Perceptual Color Analysis):",
    "lab_lightness": "  Lightness (L):",
    "lab_l_original": "    Original: {mean:.1f} ¬± {std:.1f}",
    "lab_l_sr": "    AI Result: {mean:.1f} ¬± {std:.1f}",
    "lab_a": "  a (Red-Green):",
    "lab_a_original": "    Original: {mean:.1f} ¬± {std:.1f}",
    "lab_a_sr": "    AI Result: {mean:.1f} ¬± {std:.1f}",
    "lab_b": "  b (Yellow-Blue):",
    "lab_b_original": "    Original: {mean:.1f} ¬± {std:.1f}",
    "lab_b_sr": "    AI Result: {mean:.1f} ¬± {std:.1f}",
    "color_diff_calc_gpu": "Starting color difference calculation (GPU)",
    "color_diff_calc_cpu": "Starting color difference calculation (CPU)",
    "delta_e_sr_vs_orig": "\n  SR Image vs Original ŒîE: {value:.2f}",
    "eval_delta_e_excellent": "  Evaluation: [OK] Excellent (ŒîE < 1: Indistinguishable to human eye)",
    "eval_delta_e_good": "  Evaluation: [OK] High Quality (ŒîE < 5: Acceptable range)",
    "eval_delta_e_acceptable": "  Evaluation: [WARNING] Acceptable (ŒîE < 10: Slight difference)",
    "eval_delta_e_poor": "  Evaluation: [ERROR] Poor (ŒîE ‚â• 10: Clear color difference)",
    "delta_e_model_a_vs_orig": "\n  Model A vs Original ŒîE: {value:.2f}",
    "delta_e_model_b_vs_orig": "  Model B vs Original ŒîE: {value:.2f}",
    "delta_e_model_a_closer": "  ‚Üí Model A is closer to original color (Diff: {diff:.2f})",
    "delta_e_model_b_closer": "  ‚Üí Model B is closer to original color (Diff: {diff:.2f})",
    "delta_e_note": "    (ŒîE < 1: Indistinguishable, ŒîE < 5: Acceptable, ŒîE > 10: Clear difference)",
    "delta_e_value": "\n  ŒîE (Color Difference): {value:.2f}",
    "section_11": "\n„Äê11. Frequency Domain Analysis (FFT)„Äë",
    "freq_low_original": "Original low-frequency component ratio: {ratio:.3f}",
    "freq_low_sr": "SR image low-frequency component ratio: {ratio:.3f}",
    "freq_high_original": "Original high-frequency component ratio: {ratio:.3f}",
    "freq_high_sr": "SR image high-frequency component ratio: {ratio:.3f}",
    "eval_freq_excellent": "  Evaluation: [OK] Excellent (High-frequency improved: +{improvement:.1f}%)",
    "eval_freq_good": "  Evaluation: [OK] High Quality (High-frequency preserved: {ratio:.2%})",
    "eval_freq_acceptable": "  Evaluation: [WARNING] Acceptable (Slight degradation: {ratio:.2%})",
    "eval_freq_poor": "  Evaluation: [ERROR] Poor (Significant degradation: {ratio:.2%})",
    "freq_low_img1": "Image 1 low-frequency component ratio: {ratio:.3f}",
    "freq_low_img2": "Image 2 low-frequency component ratio: {ratio:.3f}",
    "freq_high_img1": "Image 1 high-frequency component ratio: {ratio:.3f}",
    "freq_high_img2": "Image 2 high-frequency component ratio: {ratio:.3f}",
    "section_12": "\n„Äê12. Texture Analysis„Äë",
    "texture_complexity_original": "Original texture complexity: {value:.2f}",
    "texture_complexity_sr": "SR image texture complexity: {value:.2f}",
    "texture_preservation": "Preservation ratio: {ratio:.2%}",
    "eval_texture_excellent": "  Evaluation: [OK] Excellent (Texture improved: +{improvement:.1f}%)",
    "eval_texture_good": "  Evaluation: [OK] High Quality (Texture preserved: {ratio:.2%})",
    "eval_texture_acceptable": "  Evaluation: [WARNING] Acceptable (Slight degradation: {ratio:.2%})",
    "eval_texture_poor": "  Evaluation: [ERROR] Poor (Significant degradation: {ratio:.2%})"
  }
}
